{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1gUChPFd7RY",
    "outputId": "8a0eee57-39db-4d9d-b8ac-9bc019fbfd05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/MyDrive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8K7xnBOKSlm",
    "outputId": "285a9f07-c7ec-4050-9d9c-d1d7202792a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Pytorch-UNet-on-DRIVE'...\n",
      "remote: Enumerating objects: 654, done.\u001b[K\n",
      "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
      "remote: Total 654 (delta 2), reused 16 (delta 1), pack-reused 635\u001b[K\n",
      "Receiving objects: 100% (654/654), 75.59 MiB | 12.45 MiB/s, done.\n",
      "Resolving deltas: 100% (278/278), done.\n",
      "Checking out files: 100% (125/125), done.\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/Bozenton/Pytorch-UNet-on-DRIVE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "138k5Ixte-ny",
    "outputId": "9f97d7e3-e952-40eb-925c-1bc249efbe79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Pytorch-UNet-on-DRIVE\n"
     ]
    }
   ],
   "source": [
    "%cd './Pytorch-UNet-on-DRIVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MgWmBE4wKjrS",
    "outputId": "37fd880f-c137-4d75-a26a-253ebaeb574e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.12.16-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 5.3 MB/s \n",
      "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 44.3 MB/s \n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 40.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Building wheels for collected packages: pathtools\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=09a921316f185d73db7ae931f9c97679ef78b88bc6394b13ddd4359652163bea\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
      "Successfully built pathtools\n",
      "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
      "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.16\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "QYo9eC5zgBxJ",
    "outputId": "51b89011-b662-49ed-dd30-228fbd5e2e75"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.DriveDataset import DriveDataset\n",
    "from unet import UNet\n",
    "from utils.dice_score import dice_loss\n",
    "from evaluate import evaluate\n",
    "\n",
    "dir_img = Path('./datasets/training/images')\n",
    "# train_label_dir = Path('./datasets/training/1st_manual')\n",
    "dir_mask = Path('./datasets/training/1st_manual')\n",
    "dir_checkpoint = Path('./checkpoints/')\n",
    "print('Hello')\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "11WqIxtpgTgU"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(net: UNet,\n",
    "      device,\n",
    "      epochs: int = 5,\n",
    "      batch_size: int = 1,\n",
    "      learning_rate: float = 1e-5,\n",
    "      val_percent: float = 0.1,\n",
    "      save_checkpoint: bool = True,\n",
    "      img_scale: float = 0.5,\n",
    "      amp: bool = False):\n",
    "  dataset = DriveDataset(dir_img, dir_mask, img_scale, mask_suffix='_manual1')\n",
    "\n",
    "  n_val = int(len(dataset) * val_percent)\n",
    "  n_train = len(dataset) - n_val\n",
    "  train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "  loader_args = dict(batch_size=batch_size, num_workers=2, pin_memory=True)\n",
    "  train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "  val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "  experiment = wandb.init(project='UNetDRIVE', resume='allow', anonymous='must')\n",
    "  experiment.config.update(dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "                                val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale,\n",
    "                                amp=amp))\n",
    "  logging.info(f'''Starting training:\n",
    "      Epochs:          {epochs}\n",
    "      Batch size:      {batch_size}\n",
    "      Learning rate:   {learning_rate}\n",
    "      Training size:   {n_train}\n",
    "      Validation size: {n_val}\n",
    "      Checkpoints:     {save_checkpoint}\n",
    "      Device:          {device.type}\n",
    "      Images scaling:  {img_scale}\n",
    "      Mixed Precision: {amp}\n",
    "  ''')\n",
    "\n",
    "  # Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "  optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "  grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  global_step = 0\n",
    "\n",
    "  # Begin training\n",
    "  for epoch in range(1, epochs + 1):\n",
    "    net.train()\n",
    "    epoch_loss = 0\n",
    "    with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "      for batch in train_loader:\n",
    "        images = batch['image']\n",
    "        masks = batch['mask']\n",
    "        assert images.shape[1] == net.n_channels, \\\n",
    "          f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "          f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "          'the images are loaded correctly.'\n",
    "\n",
    "        images = images.to(device=device, dtype=torch.float32)\n",
    "        masks = masks.to(device=device, dtype=torch.long)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=amp):\n",
    "          masks_pred = net(images)\n",
    "          loss = criterion(masks_pred, masks) \\\n",
    "                + dice_loss(F.softmax(masks_pred, dim=1).float(),\n",
    "                      F.one_hot(masks, net.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                      multiclass=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        grad_scaler.scale(loss).backward()\n",
    "        grad_scaler.step(optimizer)\n",
    "        grad_scaler.update()\n",
    "\n",
    "        pbar.update(images.shape[0])\n",
    "        global_step += 1\n",
    "        epoch_loss += loss.item()\n",
    "        experiment.log({\n",
    "            'train loss': loss.item(),\n",
    "            'step': global_step,\n",
    "            'epoch': epoch\n",
    "        })\n",
    "        pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "        division_step = (n_train // (10 * batch_size))\n",
    "        if division_step > 0:\n",
    "          if global_step % division_step == 0:\n",
    "            histograms = {}\n",
    "            for tag, value in net.named_parameters():\n",
    "              tag = tag.replace('/', '.')\n",
    "              histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
    "              histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
    "\n",
    "            val_score = evaluate(net, val_loader, device)\n",
    "            scheduler.step(val_score)\n",
    "\n",
    "            logging.info('Validation Dice score: {}'.format(val_score))\n",
    "            experiment.log({\n",
    "              'learning rate': optimizer.param_groups[0]['lr'],\n",
    "              'validation Dice': val_score,\n",
    "              'images': wandb.Image(images[0].cpu()),\n",
    "              'masks': {\n",
    "                  'true': wandb.Image(masks[0].float().cpu()),\n",
    "                  'pred': wandb.Image(torch.softmax(masks_pred, dim=1).argmax(dim=1)[0].float().cpu()),\n",
    "              },\n",
    "              'step': global_step,\n",
    "              'epoch': epoch,\n",
    "              **histograms\n",
    "            })\n",
    "    if save_checkpoint:\n",
    "        Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(net.state_dict(), str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch)))\n",
    "        logging.info(f'Checkpoint {epoch} saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_m7mH0Npgt19",
    "outputId": "8c1301ba-e12b-4b6e-ac2f-4da30f3319b1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device cpu\n",
      "INFO: Network:\n",
      "\t3 input channels\n",
      "\t2 output channels (classes)\n",
      "\tTransposed conv upscaling\n",
      "INFO: Creating dataset with 20 images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "net = UNet(n_channels=3, n_classes=2, bilinear=False)\n",
    "\n",
    "logging.info(f'Network:\\n'\n",
    "      f'\\t{net.n_channels} input channels\\n'\n",
    "      f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "      f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
    "\n",
    "net.to(device=device)\n",
    "\n",
    "try:\n",
    "  train(net=net,\n",
    "      epochs=2,\n",
    "      batch_size=2,\n",
    "      learning_rate=1e-4,\n",
    "      device=device,\n",
    "      img_scale=1,\n",
    "      val_percent=0.2,\n",
    "      amp=False)\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
    "    logging.info('Saved interrupt')\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6-GPNHorI8e"
   },
   "outputs": [],
   "source": [
    "!python pred.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UNet-Drive.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
